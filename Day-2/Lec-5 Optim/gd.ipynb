{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-1 : Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + 4*x + 4\n",
    "\n",
    "def f_prime(x):\n",
    "    return 2*x + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(x_start, lr, itr):\n",
    "    x = x_start\n",
    "    for i in range(itr):\n",
    "        grad = f_prime(x)\n",
    "        x = x - lr * grad\n",
    "        print(f\"Iterations {i+i}: x = {x}, f'(x) = {f_prime(x)}, f(x) = {f(x)}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 0: x = -0.4, f'(x) = 3.2, f(x) = 2.56\n",
      "Iterations 2: x = -0.7200000000000001, f'(x) = 2.5599999999999996, f(x) = 1.6383999999999999\n",
      "Iterations 4: x = -0.976, f'(x) = 2.048, f(x) = 1.0485760000000002\n",
      "Iterations 6: x = -1.1808, f'(x) = 1.6383999999999999, f(x) = 0.6710886399999998\n",
      "Iterations 8: x = -1.34464, f'(x) = 1.3107199999999999, f(x) = 0.42949672959999985\n",
      "Iterations 10: x = -1.4757120000000001, f'(x) = 1.0485759999999997, f(x) = 0.27487790694399994\n",
      "Iterations 12: x = -1.5805696, f'(x) = 0.8388608, f(x) = 0.17592186044416014\n",
      "Iterations 14: x = -1.66445568, f'(x) = 0.6710886399999998, f(x) = 0.11258999068426245\n",
      "Iterations 16: x = -1.731564544, f'(x) = 0.5368709119999999, f(x) = 0.07205759403792777\n",
      "Iterations 18: x = -1.7852516352, f'(x) = 0.42949672959999985, f(x) = 0.046116860184273634\n",
      "minimum at x = -1.7852516352\n"
     ]
    }
   ],
   "source": [
    "xmin = gd(0, 0.1, 10)\n",
    "print(f\"minimum at x = {xmin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 0: x = -0.04, f'(x) = 3.92, f(x) = 3.8416\n",
      "Iterations 2: x = -0.07919999999999999, f'(x) = 3.8416, f(x) = 3.68947264\n",
      "Iterations 4: x = -0.117616, f'(x) = 3.764768, f(x) = 3.543369523456\n",
      "Iterations 6: x = -0.15526368000000002, f'(x) = 3.68947264, f(x) = 3.4030520903271424\n",
      "Iterations 8: x = -0.1921584064, f'(x) = 3.6156831872, f(x) = 3.2682912275501876\n",
      "Iterations 10: x = -0.228315238272, f'(x) = 3.543369523456, f(x) = 3.1388668949392002\n",
      "Iterations 12: x = -0.26374893350656003, f'(x) = 3.4725021329868797, f(x) = 3.0145677658996077\n",
      "Iterations 14: x = -0.29847395483642886, f'(x) = 3.4030520903271424, f(x) = 2.8951908823699832\n",
      "Iterations 16: x = -0.33250447573970027, f'(x) = 3.3349910485205996, f(x) = 2.7805413234281318\n",
      "Iterations 18: x = -0.3658543862249063, f'(x) = 3.268291227550187, f(x) = 2.670431887020378\n",
      "minimum at x = -0.3658543862249063\n"
     ]
    }
   ],
   "source": [
    "xmin = gd(0, 0.01, 10)\n",
    "print(f\"minimum at x = {xmin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Steepest GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + 10*x + 25\n",
    "\n",
    "def df(x):\n",
    "    return 2*x + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_step(x, grad, lr=1.0, dr=0.8, tr=0.00001, itr=100):\n",
    "    lr = lr\n",
    "    itr_counter = 0\n",
    "    while f(x - lr*grad) > f(x) - itr and itr_counter < itr:\n",
    "        lr = lr * dr\n",
    "        itr_counter = itr_counter + 1\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x_start, itr = 100, tr = 0.0001):\n",
    "    x = x_start\n",
    "    for i in range(itr):\n",
    "        grad = df(x)\n",
    "        lr = opt_step(x, grad, tr=tr)\n",
    "        x_new = x - lr * grad\n",
    "        if (abs(x - x_new) < tr):\n",
    "            print(f\"Convergent Iteration : {i+1}\")\n",
    "            break\n",
    "        x = x_new\n",
    "        print(f\"Iteration {i+1}, x = {x}, f(x) = {f(x)}\")\n",
    "    return x_new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergent Iteration : 1\n",
      "minimum at x = -8.148143905337993e-10\n"
     ]
    }
   ],
   "source": [
    "xmin = sgd(x_start=0)\n",
    "print(f\"minimum at x = {xmin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. simple linear regressioin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quanta",
   "language": "python",
   "name": "quanta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
